{"cells":[{"cell_type":"markdown","source":["# Q1. Question 123: \n\n# - Input: \n    - bookId(Int)                     SalesOfBookByStore (Array(Int))\n        1                               Array(30, 5, 20, 10) \n        2                               Array(20, 10) \n        3                               Array(60) \n        . \n        . \n        . \n        n \n# - output \n        1 65 \n\n        2 30 \n        3 60 \n        . \n        . \n        . \n        n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"23485bd4-17e0-481f-88de-668814518aab","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%scala\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.types.{ArrayType, IntegerType, StructField, StructType}\n\nval  book_schema =StructType(\n    List(\n      StructField(\"bookId\",IntegerType,true),\n      StructField(\"SalesOfBookByStore\",ArrayType(IntegerType),true)\n    ))\n\nimport org.apache.spark.sql.Row\nimport scala.collection.JavaConversions._//JavaConverters._\nimport org.apache.spark.sql.functions.explode\n                \nval rowData= Seq(Row(1,Seq(30,5,20,10)), \n               Row(2,Seq(20,10)), \n               Row(3,Seq(60))\n                )\n\nimport spark.implicits._\n\nval df = spark.createDataFrame(rowData,book_schema)\n\nval result = df.select($\"bookId\",explode($\"SalesOfBookByStore\") as \"SalesOfBookByStore\")\nval final_result = result.groupBy(\"bookId\").sum(\"SalesOfBookByStore\")\n\nfinal_result.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d4a2253c-5073-4ccf-83b7-5231308d5fbc","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------+-----------------------+\n|bookId|sum(SalesOfBookByStore)|\n+------+-----------------------+\n|     1|                     65|\n|     2|                     30|\n|     3|                     60|\n+------+-----------------------+\n\ncommand-165440525910122:21: warning: object JavaConversions in package collection is deprecated (since 2.12.0): use JavaConverters\nval df = spark.createDataFrame(rowData,book_schema)\n                               ^\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.types.{ArrayType, IntegerType, StructField, StructType}\nbook_schema: org.apache.spark.sql.types.StructType = StructType(StructField(bookId,IntegerType,true),StructField(SalesOfBookByStore,ArrayType(IntegerType,true),true))\nimport org.apache.spark.sql.Row\nimport scala.collection.JavaConversions._\nimport org.apache.spark.sql.functions.explode\nrowData: Seq[org.apache.spark.sql.Row] = List([1,List(30, 5, 20, 10)], [2,List(20, 10)], [3,List(60)])\nimport spark.implicits._\ndf: org.apache.spark.sql.DataFrame = [bookId: int, SalesOfBookByStore: array&lt;int&gt;]\nresult: org.apache.spark.sql.DataFrame = [bookId: int, SalesOfBookByStore: int]\nfinal_result: org.apache.spark.sql.DataFrame = [bookId: int, sum(SalesOfBookByStore): bigint]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+-----------------------+\nbookId|sum(SalesOfBookByStore)|\n+------+-----------------------+\n     1|                     65|\n     2|                     30|\n     3|                     60|\n+------+-----------------------+\n\ncommand-165440525910122:21: warning: object JavaConversions in package collection is deprecated (since 2.12.0): use JavaConverters\nval df = spark.createDataFrame(rowData,book_schema)\n                               ^\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.types.{ArrayType, IntegerType, StructField, StructType}\nbook_schema: org.apache.spark.sql.types.StructType = StructType(StructField(bookId,IntegerType,true),StructField(SalesOfBookByStore,ArrayType(IntegerType,true),true))\nimport org.apache.spark.sql.Row\nimport scala.collection.JavaConversions._\nimport org.apache.spark.sql.functions.explode\nrowData: Seq[org.apache.spark.sql.Row] = List([1,List(30, 5, 20, 10)], [2,List(20, 10)], [3,List(60)])\nimport spark.implicits._\ndf: org.apache.spark.sql.DataFrame = [bookId: int, SalesOfBookByStore: array&lt;int&gt;]\nresult: org.apache.spark.sql.DataFrame = [bookId: int, SalesOfBookByStore: int]\nfinal_result: org.apache.spark.sql.DataFrame = [bookId: int, sum(SalesOfBookByStore): bigint]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%python\n\nfrom pyspark.sql.types import StringType, StructField, StructType, ArrayType, IntegerType\nfrom pyspark.sql.functions import explode\nfrom pyspark.sql import Row\n\nbook_schema =StructType(\n    [\n      StructField(\"bookId\",IntegerType(),True),\n      StructField(\"SalesOfBookByStore\",ArrayType(IntegerType()),True)\n    ])\n\n#import org.apache.spark.sql.Row\n#import scala.collection.JavaConversions._//JavaConverters._\n#import org.apache.spark.sql.functions.explode\n       \n\nrowData= [Row(1,[30,5,20,10]), \n               Row(2,[20,10]), \n               Row(3,[60])\n            ]\n\n#import spark.implicits._\n\ndf = spark.createDataFrame(rowData,book_schema)\n\ndf1 = df.select(\"bookId\",explode('SalesOfBookByStore') )\n\nresult =  df1.selectExpr(\"bookId\",\"col as SalesOfBookByStore\")\nfinal_result = result.groupBy(\"bookId\").sum(\"SalesOfBookByStore\")\n\nfinal_result.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8b75c74c-283a-4546-918a-a38cb284cc09","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------+-----------------------+\n|bookId|sum(SalesOfBookByStore)|\n+------+-----------------------+\n|     1|                     65|\n|     2|                     30|\n|     3|                     60|\n+------+-----------------------+\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["# Q4. Given \n\n- s = \"the sky is blue\" \n\n- return \"blue is sky the\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3faa5f8f-2331-47a1-9249-8d50f7bbeada","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%scala\nval s = \"the sky is blue\" \nval split = s.split(\" \")\nvar sum = \"\"\nval result = split.reverse.fold(\"\")((x,y) => x + y +' ')\n\nprint(result) \n "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"27800fa3-5135-433d-956c-290b888193fb","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">blue is sky thes: String = the sky is blue\nsplit: Array[String] = Array(the, sky, is, blue)\nsum: String = &quot;&quot;\nresult: String = &quot;blue is sky the &quot;\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">blue is sky thes: String = the sky is blue\nsplit: Array[String] = Array(the, sky, is, blue)\nsum: String = &quot;&quot;\nresult: String = &quot;blue is sky the &quot;\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Q5.  \n# - Given: \n    date  store product     sales_val   sales_vol sales_discount_val \n    date  store product     stock_val   stock_vol \n    date  store product     order_val   order_vol \n \n# - Get below, without using Joins \n\n    date store product sales_val sales_vol sales_discount_val date store product stock_val stock_vol date store product order_val order_vol"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"46580b2a-32ce-46fa-bed8-08ca39d3d10f","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["# WAP to find out top movies with following conditions\n  1) at least 100 people should have rated for that movie.\n  2)  average rating > 4.5\n# DataSet1\n    user_id, movie_id, ratings, timestamp(hipoc time, no of seconds after 1st jan 1970)\n    1::1193::5::978300760\n    1::661::3::978302109\n    1::914::3::978301968\n    1::3408::4::978300275\n    1::2355::5::978824291\n    1::1197::3::978302268\n    1::1287::5::978302039\n    1::2804::5::978300719\n    1::594::4::978302268\n# DataSet 2\n     user_id, movie_name, movie_type\n    1::Toy Story (1995):: Animation | Children's | Comedy\n    2::Jumanji (1995):: Adventure | Children's | Fantasy\n    3::Grumpier Old Men (1995):: Comedy | Romance 4 4::Waiting to Exhale (1995):: Comedy | Drama\n    5::Father of the Bride Part II (1995):: Comedy\n    6::Heat (1995):: Action | Crime | Thriller\n    7::Sabrina (1995):: Comedy | Romance\n    8::Tom and Huck (1995):: Adventure | Children's\n    9::Sudden Death (1995)::Action\n    10::GoldenEye (1995):: Action | Adventure | Thriller\n    11::American President, The (1995):: Comedy | Drama | Romance\n    12::Dracula: Dead and Loving It (1995):: Comedy\n    13::Balto (1995):: Animation | Children's\n    14::Nixon (1995):: Drama\n    15::Cutthroat Island (1995):: Action | Adventure | Romance"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4a8af5d1-12e8-4476-8d9b-2427cb611664","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"12ea22fa-885e-4e1a-9df0-fc9ad28710ac","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Question:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d9c50c43-fba3-47bd-83cf-7dd5a1a245dd","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fab415dc-a8b1-4f2b-bff5-8f91123eb504","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ScenarioBasedQuestions","dashboards":[{"elements":[{"elementNUID":"23485bd4-17e0-481f-88de-668814518aab","dashboardResultIndex":0,"guid":"df145907-4c5a-4a43-8c6b-d97d02672a16","resultIndex":null,"options":null,"position":{"x":0,"y":0,"height":7,"width":12,"z":null},"elementType":"command"}],"guid":"7910d2c0-ae0d-49f3-9ba7-16e11047b332","layoutOption":{"stack":true,"grid":true},"version":"DashboardViewV1","nuid":"066ff7f6-bdf3-453a-b807-b259d9127ee4","origId":1845174348465935,"title":"Untitled","width":1024,"globalVars":{}}],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":165440525910121}},"nbformat":4,"nbformat_minor":0}
